<!DOCTYPE html>
<html lang="en-US">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>LM-KBC @ ISWC 2022</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.0-beta1/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-0evHe/X+R7YkIZDRvuzKMRqM+OrBnVFBL6DOitfPri4tjfHxaWutUpFmBp4vmVor" crossorigin="anonymous">

    <style>
        #content p {
            text-align: justify;
        }

        #header-description {
            font-size: 1.5em;
        }
    </style>
</head>

<body class="px-xxl-5">
    <div class="container-fluid text-center my-4">
        <h1>Knowledge Base Construction from Pre-trained Language Models (LM-KBC)</h1>
        <p>
            <a id="header-description" href="https://iswc2022.semanticweb.org/" target="_blank"
                class="text-decoration-none text-black">
                21st International Semantic Web Conference (ISWC 2022)
            </a>
        </p>
        <p>
            <a class="btn btn-primary" href="https://github.com/lm-kbc/dataset" target="_blank">
                Download dataset
            </a>
        </p>
    </div>

    <hr>

    <div class="container-fluid my-5">
        <div class="row">
            <div id="content" class="col-12 col-lg-8">
                <p>Pre-trained language models (LMs) have advanced a range of semantic tasks and have also shown promise
                    for knowledge extraction from the models itself. Although several works have explored this ability
                    in a setting called LM probing using prompting or prompt-based learning (<a
                        href="https://arxiv.org/pdf/2107.13586.pdf" target="_blank">Liu et al., 2021</a>), the viability
                    of <em>knowledge base construction</em> from LMs has not yet been explored. In this challenge, we
                    invite participants to build actual knowledge bases from LMs, for given subjects and relations. In
                    crucial difference to existing probing benchmarks like LAMA (<a
                        href="https://arxiv.org/pdf/1909.01066.pdf" target="_blank">Petroni et al., 2019</a>), we make
                    no simplifying assumptions on relation cardinalities, i.e., a subject-entity can stand in relation
                    with zero, one, or many object-entities. Furthermore, submissions need to go beyond just ranking the
                    predictions, and materialize outputs, which are evaluated by established KB metrics of precision and
                    recall.</p>

                <div id='sec-task-definition' class="my-5">
                    <h3 id="task-definition">Task Definition</h3>
                    <p>Formally, given the input subject-entity (<code>s</code>) and relation (<code>r</code>), the task
                        is to predict all the correct object-entities ({<code>o<sub>1</sub></code>,
                        <code>o<sub>2</sub></code>, ..., <code>o<sub>k</sub></code>}) using LM probing. The challenge
                        comes with two tracks: (i) a <a href="https://aclanthology.org/N19-1423/"
                            target="_blank">BERT</a> (BERT-base or BERT-large) track with low computational
                        requirements, and (ii) an open track, where participants can use any LM (e.g., <a
                            href="https://arxiv.org/pdf/1907.11692.pdf" target="blank">RoBERTa</a>, <a
                            href="https://arxiv.org/pdf/1901.02860.pdf" target="blank">Transformer-XL</a>, <a
                            href="https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf"
                            target="_blank">GPT-2</a>, <a href="https://arxiv.org/pdf/1910.13461.pdf"
                            target="blank">BART</a> etc.) of their choice.
                    </p>
                </div>
                <div id='sec-dataset' class="my-5">
                    <h3 id="dataset">Dataset</h3>
                    <p>We release a dataset (train and development) for a diverse set of 12 relations, each covering a
                        different set of subject-entities and along with complete list ground truth object-entities per
                        subject-relation-pair. The total number of object-entities varies for a given subject-relation
                        pair. The train dataset subject-relation-object triples can be used for training the language
                        models in any form, while development can be used for hyperparameter tuning. Futher details on
                        the relations are given below:</p>
                    <table class="table table-striped table-hover">
                        <thead>
                            <tr>
                                <th scope="col">Relation</th>
                                <th scope="col">Description</th>
                            </tr>
                        </thead>
                        <tbody class="table-group-divider">
                            <tr>
                                <td>CountryBordersWithCountry</td>
                                <td>country (s) shares a land border with another country (o)</td>
                            </tr>
                            <tr>
                                <td>CountryOfficialLanguage</td>
                                <td>country (s) has an official language (o)</td>
                            </tr>
                            <tr>
                                <td>RiverBasinsCountry</td>
                                <td>country (s) basins in a country (o)</td>
                            </tr>
                            <tr>
                                <td>StateSharesBorderState</td>
                                <td>state (s) of a country shares a land border with another state (o)</td>
                            </tr>
                            <tr>
                                <td>ChemicalCompoundElement</td>
                                <td>chemical compound (s) consists of an element (o)</td>
                            </tr>
                            <tr>
                                <td>PersonInstrument</td>
                                <td>person (s) plays an instrument (o)</td>
                            </tr>
                            <tr>
                                <td>PersonLanguage</td>
                                <td>person (s) speaks in a language (o)</td>
                            </tr>
                            <tr>
                                <td>PersonEmployer</td>
                                <td>person (s) is or was employed by a company (o)</td>
                            </tr>
                            <tr>
                                <td>PersonProfession</td>
                                <td>person (s) held a profession (o)</td>
                            </tr>
                            <tr>
                                <td>PersonPlaceOfDeath</td>
                                <td>person (s) died at a location (o)</td>
                            </tr>
                            <tr>
                                <td>PersonCauseOfDeath</td>
                                <td>person (s) died due to a cause (o)</td>
                            </tr>
                            <tr>
                                <td>CompanyParentOrganization</td>
                                <td>company (s) has another company (o) as its parent organization</td>
                            </tr>
                        </tbody>
                    </table>
                    <p>Each row in the dataset files constitutes one triple, of (1) subject-entity, (2) relation, and
                        (3) object-entity. For (3), we sometimes provide multiple aliases, where outputing any one of
                        them is sufficient. In particular, to faciliate usage of LMs like BERT (which are constrained by
                        single-token predictions), we provide atleast one valid single-token form for every object.
                        To represent subjects with zero valid objects, we introduce a special value <em>NONE</em>. Those
                        subjects will then have one row with that value, e.g., ( Apple Inc., CompanyParentOrganization,
                        <em>NONE</em>).
                    </p>
                </div>
                <div id='sec-task-evaluation' class="my-5">
                    <h3 id="task-evaluation">Task Evaluation</h3>
                    <p>We use a standard KBC evaluation metric, the F1-score (based on the combination of precision and
                        recall), to compare the predicted object-entities with true object-entities on the hidden test
                        dataset. We release a <a href="https://github.com/lm-kbc/dataset/blob/main/bert.py"
                            target="_blank">baseline</a>
                        implementation and <a href="https://github.com/lm-kbc/dataset/blob/main/evaluation.py"
                            target="_blank">evaluation</a> script. The baseline model probes the BERT language model
                        using a sample prompt like <em>"China shares border with [MASK]"</em> and selects
                        object-entities predicted in the [MASK] position with greater than or equal to 0.5 likelihood as
                        outputs. Participants can use the evaluation script to compute the F1-score for assessing the
                        performance of their systems.</p>
                    <!-- <p>For general questions or discussion please use the Google group:
                        <a href="https://groups.google.com/g/lm-kbc"
                            target="_blank">https://groups.google.com/g/lm-kbc</a>.
                    </p> -->
                </div>
                <div id='sec-submission-details' class="my-5">
                    <h3 id="submission-details">Submission Details</h3>
                    <p>Participants are required to submit (1) their system implementing the LM probing approach, (2)
                        the output for the test dataset subject-entites, (3) a system description in PDF format (no
                        longer than 12 pages, LNCS style). The test dataset is initially hidden to preserve the
                        integrity of results, and is released 3 days before system submission deadline. The output files
                        for the test subject-entities must be formatted like the train dataset files (one for each
                        relation), and submitted along with the system. Top performing systems will get an opportunity
                        to present their ideas and results during the ISWC 2022 conference, and will be published in the
                        CEUR challenge proceedings. System descriptions should be submitted on <a
                            href="https://easychair.org/conferences/?conf=lmkbc2022" target="_blank">Easychair</a>.</p>
                </div>
                <div id='sec-organizers' class="my-5">
                    <h3 id="organizers">Organizers</h3>
                    <ul>
                        <li><a href="https://people.mpi-inf.mpg.de/~ssinghan/" target="_blank">Sneha Singhania</a>, Max
                            Planck
                            Institute for Informatics, Germany</li>
                        <li><a href="https://www.tuan-phong.com/" target="_blank">Tuan-Phong Nguyen</a>, Max Planck
                            Institute
                            for Informatics, Germany</li>
                        <li><a href="http://simonrazniewski.com/" target="_blank">Simon Razniewski</a>, Max Planck
                            Institute
                            for
                            Informatics, Germany</li>
                    </ul>
                </div>
            </div>
            <div id="aside" class="col-12 col-lg-4">
                <div class="px-xxl-5">
                    <div class="mb-4">
                        <div class="text-center mb-4">
                            <h4>Important Dates</h3>
                        </div>
                        <table class="table table-bordered">
                            <thead>
                                <tr>
                                    <th>Activity</th>
                                    <th class="text-center">Dates</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td>Dataset (train and val) release</td>
                                    <td class="text-center">17 May 2022</td>
                                </tr>
                                <tr>
                                    <td>Dataset (test) release</td>
                                    <td class="text-center">11 July 2022</td>
                                </tr>
                                <tr>
                                    <td>System + test dataset predictions submission</td>
                                    <td class="text-center">14 July 2022</td>
                                </tr>
                                <tr>
                                    <td>Winner Announcement</td>
                                    <td class="text-center">15 August 2022</td>
                                </tr>
                                <tr>
                                    <td>ISWC Invitations</td>
                                    <td class="text-center">15 August 2022</td>
                                </tr>
                                <tr>
                                    <td>ISWC Presentations</td>
                                    <td class="text-center">23-27 October 2022</td>
                                </tr>
                            </tbody>
                        </table>
                    </div>

                    <hr>

                    <div class="mb-4">
                        <div class="text-center mb-4">
                            <h4>Contact</h4>
                        </div>
                        <div class="px-xxl-4">
                            <p>
                                For general questions or discussion please use the
                                <a href="https://groups.google.com/g/lm-kbc" target="_blank">Google group</a>.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.0-beta1/dist/js/bootstrap.bundle.min.js"
        integrity="sha384-pprn3073KE6tl6bjs2QrFaJGz5/SUsLqktiwsUTF55Jfv3qYSDhgCecCxMW52nD2"
        crossorigin="anonymous"></script>
</body>

</html>