<html>

<head>
<meta http-equiv=Content-Type content="text/html; charset=windows-1252">
<meta name=Generator content="Microsoft Word 15 (filtered)">
<style>
<!--
 /* Font Definitions */
 @font-face
	{font-family:Wingdings;
	panose-1:5 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Cambria Math";
	panose-1:2 4 5 3 5 4 6 3 2 4;}
@font-face
	{font-family:Calibri;
	panose-1:2 15 5 2 2 2 4 3 2 4;}
 /* Style Definitions */
 p.MsoNormal, li.MsoNormal, div.MsoNormal
	{margin-top:0in;
	margin-right:0in;
	margin-bottom:8.0pt;
	margin-left:0in;
	line-height:105%;
	font-size:11.0pt;
	font-family:"Calibri",sans-serif;}
h2
	{mso-style-link:"Heading 2 Char";
	margin-top:2.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	line-height:105%;
	page-break-after:avoid;
	font-size:16.0pt;
	font-family:"Arial",sans-serif;
	color:black;
	font-weight:normal;}
a:link, span.MsoHyperlink
	{color:blue;
	text-decoration:underline;}
p.MsoPlainText, li.MsoPlainText, div.MsoPlainText
	{mso-style-link:"Plain Text Char";
	margin:0in;
	font-size:11.0pt;
	font-family:"Calibri",sans-serif;}
p.MsoListParagraph, li.MsoListParagraph, div.MsoListParagraph
	{margin-top:0in;
	margin-right:0in;
	margin-bottom:8.0pt;
	margin-left:.5in;
	line-height:105%;
	font-size:11.0pt;
	font-family:"Calibri",sans-serif;}
span.Heading2Char
	{mso-style-name:"Heading 2 Char";
	mso-style-link:"Heading 2";
	font-family:"Arial",sans-serif;
	color:black;}
span.PlainTextChar
	{mso-style-name:"Plain Text Char";
	mso-style-link:"Plain Text";
	font-family:"Calibri",sans-serif;}
.MsoChpDefault
	{font-size:10.0pt;}
.MsoPapDefault
	{margin-bottom:8.0pt;
	line-height:105%;}
@page WordSection1
	{size:595.3pt 841.9pt;
	margin:1.0in 1.0in 1.0in 1.0in;}
div.WordSection1
	{page:WordSection1;}
 /* List Definitions */
 ol
	{margin-bottom:0in;}
ul
	{margin-bottom:0in;}
-->
</style>

</head>

<body lang=EN-US link=blue vlink="#954F72" style='word-wrap:break-word'>

<div class=WordSection1>

<p class=MsoNormal style='line-height:normal'><b><span style='font-size:24.0pt;
font-family:"Arial",sans-serif'>Knowledge Base Construction from Pre-trained
Language Models (KBC-LM) </span></b></p>

<p class=MsoNormal><span style='font-family:"Arial",sans-serif'><a
href="https://iswc2023.semanticweb.org/" target="_blank">Workshop @ 22<sup>nd</sup>
International Semantic Web Conference (ISWC 2023) </a></span></p>

<p class=MsoNormal><span style='font-family:"Arial",sans-serif'>&nbsp;</span></p>

<h2 style='margin-bottom:6.0pt'>Overview</h2>

<p class=MsoPlainText><span style='font-family:"Arial",sans-serif'>Language models
(LMs), such as chatGPT, BERT, and T5, have demonstrated remarkable outcomes in
numerous AI applications. Research has shown that these models implicitly
capture vast amounts of factual knowledge within their parameters, resulting in
a remarkable performance in knowledge-intensive applications. The seminal paper
``Language Models as Knowledge Bases?'' sparked interest in the spectrum
between language models and knowledge graphs, leading to a diverse range of
research on the usage of LMs for knowledge base construction. This research
includes:</span></p>

<p class=MsoPlainText style='margin-left:.5in;text-indent:-.25in'><span
style='font-family:"Arial",sans-serif'>(1)<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;
</span></span><span style='font-family:"Arial",sans-serif'>utilizing
pre-trained LMs for knowledge base completion and construction tasks,</span></p>

<p class=MsoPlainText style='margin-left:.5in;text-indent:-.25in'><span
style='font-family:"Arial",sans-serif'>(2)<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;
</span></span><span style='font-family:"Arial",sans-serif'>performing
information extraction tasks, like entity linking and relation extraction, and</span></p>

<p class=MsoPlainText style='margin-left:.5in;text-indent:-.25in'><span
style='font-family:"Arial",sans-serif'>(3)<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;
</span></span><span style='font-family:"Arial",sans-serif'>utilizing knowledge
graphs to support LM applications.</span></p>

<p class=MsoPlainText><span style='font-family:"Arial",sans-serif'>In the first
edition of the LM-KBC workshop, we aim to give space to the emerging academic
community that investigates these topics, host extended discussions around the
LM-KBC Semantic Web challenge, and enable an informal exchange of researchers
and practitioners.</span></p>

<p class=MsoPlainText><span style='font-family:"Arial",sans-serif'>&nbsp;</span></p>

<h2 style='margin-bottom:6.0pt'>Topics</h2>

<p class=MsoNormal><span style='font-family:"Arial",sans-serif'>We invite contributions
on the following topics:</span></p>

<p class=MsoListParagraph style='margin-bottom:0in;text-indent:-.25in'><span
style='font-family:"Arial",sans-serif'>-<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span><span style='font-family:"Arial",sans-serif'>Entity recognition
and disambiguation with LMs</span></span></p>

<p class=MsoListParagraph style='margin-bottom:0in;text-indent:-.25in'><span
style='font-family:"Arial",sans-serif'>-<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span><span style='font-family:"Arial",sans-serif'>Relation extraction
with LMs</span></span></p>

<p class=MsoListParagraph style='margin-bottom:0in;text-indent:-.25in'><span
style='font-family:"Arial",sans-serif'>-<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span><span style='font-family:"Arial",sans-serif'>Zero-shot and
few-shot knowledge extraction from LMs</span></span></p>

<p class=MsoListParagraph style='margin-bottom:0in;text-indent:-.25in'><span
style='font-family:"Arial",sans-serif'>-<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span><span style='font-family:"Arial",sans-serif'>Consistency of LMs</span></span></p>

<p class=MsoListParagraph style='margin-bottom:0in;text-indent:-.25in'><span
style='font-family:"Arial",sans-serif'>-<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span><span style='font-family:"Arial",sans-serif'>Knowledge
consolidation with LMs</span></span></p>

<p class=MsoListParagraph style='margin-bottom:0in;text-indent:-.25in'><span
style='font-family:"Arial",sans-serif'>-<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span><span style='font-family:"Arial",sans-serif'>Comparisons of LMs
for KBC tasks</span></span></p>

<p class=MsoListParagraph style='margin-bottom:0in;text-indent:-.25in'><span
style='font-family:"Arial",sans-serif'>-<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span><span style='font-family:"Arial",sans-serif'>Methodological
contributions on training and fine-tuning LMs for KBC tasks</span></span></p>

<p class=MsoListParagraph style='margin-bottom:0in;text-indent:-.25in'><span
style='font-family:"Arial",sans-serif'>-<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span><span style='font-family:"Arial",sans-serif'>Evaluations of
downstream capabilities of LM-based KGs in tasks like QA</span></span></p>

<p class=MsoListParagraph style='margin-bottom:6.0pt;text-indent:-.25in'><span
style='font-family:"Arial",sans-serif'>-<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span><span style='font-family:"Arial",sans-serif'>Designing robust
prompts for large language model probin</span>g</span></p>

<p class=MsoNormal><span style='font-family:"Arial",sans-serif'>We invite two
types of submissions:</span></p>

<p class=MsoListParagraph style='text-indent:-.25in'><span style='font-family:
"Arial",sans-serif'>(1<b>)</b></span><b><span style='font-size:7.0pt;
line-height:105%;font-family:"Arial",sans-serif'>&nbsp;&nbsp; </span></b><b><span
style='font-family:"Arial",sans-serif'>Novel research contributions</span></b><span
style='font-family:"Arial",sans-serif'>.</span></p>

<p class=MsoListParagraph style='text-indent:-.25in'><span style='font-family:
"Arial",sans-serif'>(2)</span><span style='font-size:7.0pt;line-height:105%;
font-family:"Arial",sans-serif'>&nbsp;&nbsp; </span><b><span style='font-family:
"Arial",sans-serif'>Already published papers</span></b><span style='font-family:
"Arial",sans-serif'> (these will be presentation-only, and not part of the workshop
proceedings).</span></p>

<p class=MsoListParagraph style='margin-left:.25in;text-indent:-.25in'><span
style='font-family:"Arial",sans-serif'>Novel research papers can be either full
papers (ca. 8-12 pages), or short papers presenting smaller or preliminary
results (typically 3-6 pages). We also accept demo and position papers.</span></p>

<p class=MsoListParagraph style='margin-left:.25in;text-indent:-.25in'><span
style='font-family:"Arial",sans-serif'>Check out also the <a
href="https://lm-kbc.github.io/challenge2023/">LM-KBC challenge</a> for further
options to contribute to the workshop.</span></p>

<p class=MsoNormal style='margin-bottom:0in;line-height:normal'><span
style='font-family:"Arial",sans-serif'>&nbsp;</span></p>

<h2 style='margin-bottom:6.0pt'>Submission and review process</h2>

<p class=MsoNormal style='margin-bottom:0in;line-height:normal'><span
style='font-family:"Arial",sans-serif'>Papers will be peer-reviewed by at least
three researchers using a double-blind review. Selected papers will be
published on CEUR (if the authors agree to have their papers published). </span></p>

<p class=MsoNormal style='margin-bottom:0in;line-height:normal'><span
style='font-family:"Arial",sans-serif'>&nbsp;</span></p>

<p class=MsoNormal style='margin-bottom:0in;line-height:normal'><span
style='font-family:"Arial",sans-serif'>All papers need to be formatted according
to the CEUR workshop proceedings. A template for this workshop is available <a
href="https://www.overleaf.com/read/dwjshwhrqwzw">here</a>.</span></p>

<p class=MsoNormal style='margin-bottom:0in;line-height:normal'><span
style='font-family:"Arial",sans-serif'>&nbsp;</span></p>

<p class=MsoNormal style='margin-bottom:0in;line-height:normal'><span
style='font-family:"Arial",sans-serif'>All papers need to be submitted on <a
href="https://openreview.net/group?id=swsa.semanticweb.org/ISWC/2023/Workshop/KBC-LM">Openreview</a>.</span></p>

<p class=MsoNormal style='margin-bottom:0in;line-height:normal'><span
style='font-family:"Arial",sans-serif'><br>
<span style='transform: scaleX(0.99093)' role=presentation>Robert Bosch GmbH
has signaled that they would likely sponsor a best</span> paper award over 500
Euro.</span></p>

<p class=MsoNormal style='margin-bottom:0in;line-height:normal'><span
style='font-family:"Arial",sans-serif'>&nbsp;</span></p>

<h2 style='margin-bottom:6.0pt'>Important dates</h2>

<p class=MsoNormal style='margin-bottom:0in;line-height:normal'><span
style='font-family:"Arial",sans-serif'>- Papers due: July 31, 2023</span></p>

<p class=MsoNormal style='margin-bottom:0in;line-height:normal'><span
style='font-family:"Arial",sans-serif'>- Notification to authors: August 31,
2023</span></p>

<p class=MsoNormal style='margin-bottom:0in;line-height:normal'><span
style='font-family:"Arial",sans-serif'>- Camera-ready deadline: September 14,
2023</span></p>

<p class=MsoNormal style='margin-bottom:0in;line-height:normal'><span
style='font-family:"Arial",sans-serif'>- Workshop dates: 6 or 7 November 2023</span></p>

<p class=MsoNormal><span style='font-family:"Arial",sans-serif'>&nbsp;</span></p>

<h2 style='margin-bottom:6.0pt'>Tentative schedule</h2>

<p class=MsoNormal style='margin-bottom:0in;line-height:normal'><span
style='font-family:"Arial",sans-serif'>The idea of this workshop is to provide
a focused venue for informal exchange around LMs for KB construction. In
particular, we plan to devote space to extended presentations of participants
of the LM-KBC ISWC challenge (where the 1-hour ISWC conference slot will only
allow presentations of the winners). Furthermore, we plan to make this a hybrid
event to lower the entry barrier for participants.</span></p>

<p class=MsoNormal style='margin-bottom:0in;line-height:normal'><span
style='font-size:12.0pt;font-family:"Arial",sans-serif'><br>
</span><span style='font-family:"Arial",sans-serif'>- 08:30-08:45: Welcome</span><span
style='font-size:12.0pt;font-family:"Arial",sans-serif'><br>
</span><span style='font-family:"Arial",sans-serif'>- 08:45-09:30: Keynote</span><span
style='font-size:12.0pt;font-family:"Arial",sans-serif'><br>
</span><span style='font-family:"Arial",sans-serif'>- 09:30-10:30: Paper presentations
1</span><span style='font-size:12.0pt;font-family:"Arial",sans-serif'><br>
</span><span style='font-family:"Arial",sans-serif'>- 10:30-10:50: Coffee break</span><span
style='font-size:12.0pt;font-family:"Arial",sans-serif'><br>
</span><span style='font-family:"Arial",sans-serif'>- 10:50-11:20: Paper
presentations 2</span></p>

<p class=MsoNormal style='margin-bottom:0in;line-height:normal'><span
style='font-family:"Arial",sans-serif'>- 11:20-12:20: <a
href="https://lm-kbc.github.io/challenge2023/">LM-KBC challenge</a> presentations</span><span
style='font-size:12.0pt;font-family:"Arial",sans-serif'><br>
</span><span style='font-family:"Arial",sans-serif'>- 12:20-12:30: Closing
ceremony</span></p>

<p class=MsoNormal style='margin-bottom:0in;line-height:normal'><span
style='font-family:"Arial",sans-serif'>&nbsp;</span></p>

<p class=MsoNormal style='margin-bottom:0in;line-height:normal'><span
style='font-family:"Arial",sans-serif'>* We do not yet know whether the
workshop happens in the morning or in the afternoon.</span></p>

<p class=MsoNormal style='margin-bottom:0in;line-height:normal'><span
style='font-family:"Arial",sans-serif'>&nbsp;</span></p>

<h2 style='margin-bottom:6.0pt'>Chairs</h2>

<p class=MsoNormal style='margin-bottom:0in;line-height:normal'><b><span
style='font-family:"Arial",sans-serif'>Jan-Christoph Kalo</span></b><span
style='font-family:"Arial",sans-serif'><span role=presentation> </span><span
style='transform: scaleX(0.975008)' role=presentation>is a postdoctoral
researcher at the Learning and Reasoning Group at the Vrije Universiteit
Amsterdam. His research focus is on machine</span> learning methods,
particularly language models, for knowledge base construction and knowledge
management. He is co-organizing this year's LM-KBC challenge at ISWC and has
been part of the PC of ISWC and ESWC.</span></p>

<p class=MsoNormal style='margin-bottom:0in;line-height:normal'><b><span
style='font-family:"Arial",sans-serif'>Simon Razniewski</span></b><span
style='font-family:"Arial",sans-serif'><span role=presentation> </span><span
style='transform: scaleX(0.997191)' role=presentation>is a research scientist
in the NLP and Neuro-Symbolic</span> AI group at the Bosch Center for AI. He
has previously organized the Wikidata workshop @ ISWC, and the LM-KBC challenge
2022. He has also held senior roles in program committees of major conferences
such as IJCAI’21 and EACL’23 (area chair), or ISWC’20 and CIKM’20 (senior PC
member).<br role=presentation>
<b><span style='transform: scaleX(1.10947)' role=presentation>Sneha Singhania</span></b><span
role=presentation> </span><span style='transform: scaleX(1.06489)' role=presentation>is
a PhD student at the Max-Planck Institute for Informatics. Her research focuses
on enabling machines to select and utilize high-</span>quality information
sources, with an awareness of unknowns, for knowledge base (KB) construction.
She co-organized the LM-KBC’22 challenge and has held PC roles at ACL, CIKM, ISWC,
and ESWC.<br role=presentation>
<b><span style='transform: scaleX(1.19841)' role=presentation>Jeff Z. Pan</span></b><span
role=presentation> </span><span style='transform: scaleX(1.05571)' role=presentation>is
a chair of the Knowledge Graph Group at the Alan Turing</span> Institute and is
a member of the School of Informatics at The University of Edinburgh. He is an
Editor of the Journal of Web Semantics (JoWS) and a Programme Chair of the 19th
International Semantic Web Conference (ISWC 2020), the premier international
forum for the Semantic Web / Knowledge Graph / Linked Data communities.</span></p>

<p class=MsoNormal style='margin-bottom:0in;line-height:normal'><span
style='font-family:"Arial",sans-serif'>&nbsp;</span></p>

<h2 style='margin-bottom:6.0pt'>Selected references</h2>

<p class=MsoNormal style='margin-bottom:0in;line-height:normal'><span
style='font-family:"Arial",sans-serif'>- Petroni, F., Rocktaeschel, T., Riedel,
S., Lewis, P., Bakhtin, A., Wu, Y., Miller, A.: Language models as knowledge
bases? EMNLP, 2019</span></p>

<p class=MsoNormal style='margin-bottom:0in;line-height:normal'><span
style='font-family:"Arial",sans-serif'>- LM-KBC: Knowledge Base Construction
from Pre-trained Language Models, Sneha Singhania, Tuan-Phong Nguyen, Simon
Razniewski, CEUR-WS, 2022</span></p>

<p class=MsoNormal style='margin-bottom:0in;line-height:normal'><span lang=DE
style='font-family:"Arial",sans-serif'>- Blerta Veselhi, Sneha Singhania, Simon
Razniewski, Gerhard Weikum. </span><span style='font-family:"Arial",sans-serif'>Evaluating
Language Models for Knowledge Base Completion, ESWC, 2023</span></p>

<p class=MsoNormal style='margin-bottom:0in;line-height:normal'><span
style='font-family:"Arial",sans-serif'>- Alivanistos, Dimitrios, Selene Baez
Santamaria, Michael Cochez, Jan-Christoph Kalo, Emile van Krieken, and Thiviyan
Thanapalasingam. &quot;Prompting as Probing: Using Language Models for
Knowledge Base Construction.&quot; LM-KBC, 2022.</span></p>

<p class=MsoNormal style='margin-bottom:0in;line-height:normal'><span
style='font-family:"Arial",sans-serif'>- Simon Razniewski, Andrew Yates, Nora
Kassner, Gerhard Weikum. Language Models As or For Knowledge Bases, DL4KG@ISWC,
2021</span></p>

<p class=MsoNormal style='margin-bottom:0in;line-height:normal'><span
style='font-family:"Arial",sans-serif'>- KAMEL: Knowledge Analysis with
Multitoken Entities in Language Models, JC Kalo, L Fichtel, AKBC 2022</span></p>

<p class=MsoNormal style='margin-bottom:0in;line-height:normal'><span
style='font-family:"Arial",sans-serif'>- Cohen, Roi, et al. &quot;Crawling The
Internal Knowledge-Base of Language Models.&quot; Findings of EACL 2023.</span></p>

<p class=MsoNormal style='margin-bottom:0in;line-height:normal'><span
style='font-family:"Arial",sans-serif'>- How much knowledge can you pack into
the parameters of a language model? Roberts, Adam, Colin Raffel, and Noam
Shazeer. &quot;How Much Knowledge Can You Pack Into the Parameters of a
Language Model?.&quot; EMNLP 2020.</span></p>

</div>

</body>

</html>
