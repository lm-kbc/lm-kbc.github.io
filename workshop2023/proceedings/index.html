<!DOCTYPE html>
<!-- CEURVERSION=2020-07-09 -->
<html lang="en">
<head>
<meta http-equiv="Content-type" content="text/html;charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<link rel="stylesheet" type="text/css" href="../ceur-ws.css">
<title>CEUR-WS.org/Vol-XXX - Workshop on Publishing Papers with CEUR-WS 2023</title>
</head>
<!--CEURLANG=eng -->
<body>

<table style="border: 0; border-spacing: 0; border-collapse: collapse; width: 95%">
<tbody><tr>
<td style="text-align: left; vertical-align: middle">
<a href="https://ceur-ws.org/"><div id="CEURWSLOGO"></div></a>
</td>
<td style="text-align: right; vertical-align: middle">
<div style="float:left" id="CEURCCBY"></div>
<span class="CEURVOLNR">Vol-XXX</span> <br>
<span class="CEURURN">urn:nbn:de:0074-XXX-C</span>
<p class="unobtrusive copyright" style="text-align: justify">Copyright &copy; 2023 for 
the individual papers by the papers' authors. 
Copyright &copy; <span class="CEURPUBYEAR">2023</span> for the volume
as a collection by its editors.
This volume and its papers are published under the
Creative Commons License Attribution 4.0 International
<A HREF="https://creativecommons.org/licenses/by/4.0/">(<span class="CEURLIC">CC BY 4.0</span>)</A>.</p>
</td>
</tr>
</tbody></table>

<hr>

<br><br><br>

<h1><a href="https://lm-kbc.github.io/"><span class="CEURVOLACRONYM">KBC-LM + LM-KBC 2023</span></a><br>
<span class="CEURVOLTITLE">Joint proceedings of the KBC-LM workshop and the LM-KBC challenge @ ISWC 2023</span></h1>
<br>

<h3>
<span class="CEURFULLTITLE">Joint proceedings of the 1st workshop on Knowledge Base Construction from Pre-Trained Language Models (KBC-LM) and the 2nd challenge on Language Models for Knowledge Base Construction (LM-KBC)</span><br>
co-located with the 22nd International Semantic Web Conference (<span class="CEURCOLOCATED">ISWC 2023</span>)<br>
</h3>
<h3><span class="CEURLOCTIME">Athens, Greece, November 6, 2023</span>.</h3> 

<br>
<b> Edited by </b>
<p>

</p><h3>
   <span class="CEURVOLEDITOR">Simon Razniewski</span> *<br>
   <span class="CEURVOLEDITOR">Jan-Christoph Kalo</span> **<br>
   <span class="CEURVOLEDITOR">Sneha Singhania</span> ***<br>
   <span class="CEURVOLEDITOR">Jeff Z. Pan</span> ****<br>
   
   

</h3>

* Bosch Center for AI<br>
** VU Amsterdam<br>
*** MPI Informatics<br>
**** University of Edinburgh
Huawei Technology R&D UK<br>
  <br>

<hr>

<br><br><br>

<div class="CEURTOC">
<h2> Table of Contents </h2>


<ul>
<li id="paper1"><a href="paper1.pdf">Preface: KBC-LM Workshop 2023</a><br>
Jan-Christoph Kalo, Sneha Singhania, Simon Razniewski, Jeff Z. Pan
<br>
</li>
<li id="paper2"><a href="paper2.pdf">Preface: LM-KBC Challenge 2023</a><br>
Sneha Singhania, Jan-Christoph Kalo, Simon Razniewski, Jeff Z. Pan
<br>
<br>
Summary: There were a total of <span class="CEURSUBMITTEDPAPERS">15</span> submissions to both events (8 for workshop, 7 for challenge). We accepted <span class="CEURACCEPTEDPAPERS">14</span> papers for this volume.
</li>
</ul>



<h3><span class="CEURSESSION">KBC-LM Workshop</span></h3>
<ul>

<li id="paper3"><a href="paper3.pdf"> <span class="CEURTITLE">Language Models as Knowledge Bases for Visual Word Sense Disambiguation</span></a> <span class="CEURAUTHOR">Anastasia Kritharoula</span>, <span class="CEURAUTHOR">Maria Lymperaiou</span>, <span class="CEURAUTHOR">Giorgos Stamou</span> </li> 
 <li id="paper4"><a href="paper4.pdf"> <span class="CEURTITLE">Extracting Geographic Knowledge from Large Language Models: An Experiment</span></a> <span class="CEURAUTHOR">Konstantinos Salmas</span>, <span class="CEURAUTHOR">Despina Athanasia Pantazi</span>, <span class="CEURAUTHOR">Manolis Koubarakis</span> </li> 
 <li id="paper5"><a href="paper5.pdf"> <span class="CEURTITLE">Cross-validation of Answers with SUMO and GPT</span></a> <span class="CEURAUTHOR">Dan Lupu</span>, <span class="CEURAUTHOR">Adrian Groza</span>, <span class="CEURAUTHOR">Adam Pease</span> </li> 
 <li id="paper6"><a href="paper6.pdf"> <span class="CEURTITLE">Do Instruction-tuned Large Language Models Help with Relation Extraction?</span></a> <span class="CEURAUTHOR">Xue Li</span>, <span class="CEURAUTHOR">Fina Polat</span>, <span class="CEURAUTHOR">Paul Groth</span> </li> 
 <li id="paper7"><a href="paper7.pdf"> <span class="CEURTITLE">Towards Ontology Construction with Language Models</span></a> <span class="CEURAUTHOR">Maurice Funk</span>, <span class="CEURAUTHOR">Simon Hosemann</span>, <span class="CEURAUTHOR">Jean Christoph Jung</span>, <span class="CEURAUTHOR">Carsten Lutz</span> </li> 
 <li id="paper8"><a href="paper8.pdf"> <span class="CEURTITLE">Towards syntax-aware pretraining and prompt engineering for knowledge retrieval from large language models</span></a> <span class="CEURAUTHOR">Stefan Dietze</span>, <span class="CEURAUTHOR">Hajira Jabeen</span>, <span class="CEURAUTHOR">Laura Kallmeyer</span>, <span class="CEURAUTHOR">Stephan Linzbach</span> </li> 
 <li id="paper9"><a href="paper9.pdf"> <span class="CEURTITLE">Can large language models generate salient negative statements?</span></a> <span class="CEURAUTHOR">Hiba Arnaout</span>, <span class="CEURAUTHOR">Simon Razniewski</span> </li>

</ul>



<h3><span class="CEURSESSION">LM-KBC Challenge</span></h3>
<ul>

<li id="paper10"><a href="paper10.pdf"> <span class="CEURTITLE">Limits of Zero-shot Probing on Object Prediction</span></a> <span class="CEURAUTHOR">Shrestha Ghosh</span>, </li> 
<li id="paper11"><a href="paper11.pdf"> <span class="CEURTITLE">Knowledge-centric Prompt Composition for Knowledge Base Construction from Pre-trained Language Models</span></a> <span class="CEURAUTHOR">Xue Li</span>, <span class="CEURAUTHOR">Anthony James Hughes</span>, <span class="CEURAUTHOR">Majlinda Llugiqi</span>, <span class="CEURAUTHOR">Fina Polat</span>, <span class="CEURAUTHOR">Paul Groth</span>, <span class="CEURAUTHOR">Fajar J. Ekaputra</span> </li> 
<li id="paper12"><a href="paper12.pdf"> <span class="CEURTITLE">Enhancing Knowledge Base Construction from Pre-trained Language Models using Prompt Ensembles</span></a> <span class="CEURAUTHOR">Fabian Biester</span>, <span class="CEURAUTHOR">Daniel Del Gaudio</span>, <span class="CEURAUTHOR">Mohamed Abdelaal</span> </li> 
<li id="paper13"><a href="paper13.pdf"> <span class="CEURTITLE">Expanding the Vocabulary of BERT for Knowledge Base Construction</span></a> <span class="CEURAUTHOR">Dong Yang</span>, <span class="CEURAUTHOR">XU Wang</span>, <span class="CEURAUTHOR">Remzi Celebi</span> </li> 
<li id="paper14"><a href="paper14.pdf"> <span class="CEURTITLE">Broadening BERT vocabulary for Knowledge Graph Construction using Wikipedia2Vec</span></a> <span class="CEURAUTHOR">Debanjali Biswas</span>, <span class="CEURAUTHOR">Stephan Linzbach</span>, <span class="CEURAUTHOR">Dimitar Dimitrov</span>, <span class="CEURAUTHOR">Hajira Jabeen</span>, <span class="CEURAUTHOR">Stefan Dietze</span> </li> 
<li id="paper15"><a href="paper15.pdf"> <span class="CEURTITLE">LLM2KB: Constructing Knowledge Bases using instruction tuned context aware Large Language Models</span></a> <span class="CEURAUTHOR">Anmol Nayak</span>, <span class="CEURAUTHOR">Hariprasad Timmapathini</span> </li> 
<li id="paper16"><a href="paper16.pdf"> <span class="CEURTITLE">Using Large Language Models for Knowledge Engineering (LLMKE): A Case Study on Wikidata</span></a> <span class="CEURAUTHOR">Bohui Zhang</span>, <span class="CEURAUTHOR">Ioannis Reklos</span>, <span class="CEURAUTHOR">Nitisha Jain</span>, <span class="CEURAUTHOR">Albert Meroño-Peñuela</span>, <span class="CEURAUTHOR">Elena Simperl</span> </li>

</ul>




</div>


<hr>
<span class="unobtrusive">
2023-09-30: submitted by Simon Razniewski, 
            metadata incl. bibliographic data published under <A HREF="https://creativecommons.org/publicdomain/zero/1.0/">Creative Commons CC0</A><br>
<span class="CEURPUBDATE">2023-mm-dd</span>: published on CEUR Workshop Proceedings (CEUR-WS.org, ISSN 1613-0073)
	|<a href="https://validator.w3.org/nu/?doc=http%3A%2F%2Fceur-ws.org%2FVol-XXX%2F">valid HTML5</a>|
</span>
</body></html>
